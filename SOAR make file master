HOST=127.0.0.1
THEHIVE_SERVER_NAME=thehive.acds.net.in
CORTEX_SERVER_NAME=cortex.acds.net.in
HIVE_VERSION=4.1.9-1
CORTEX_VERSION=3.1.1-1
ELASTICSEARCH_VERSION=7.11.1
NGINX_VERSION=1.19.5
CASSANDRA_VERSION=3.11
BACKEND_VERSION=0.9.52
FRONTEND_VERSION=0.9.52
ORBORUS_VERSION=0.9.56
PLUGINS_DIR=plugins
BUILD_DIR=build
DOCKER_DIR=docker/docker-thehive
TMP_DOCKER_DIR=docker-thehive
SHUFFLE_DOCKER_DIR=Shuffle/Docker/docker-shuffle
OUT_DIR=release
BUILD=$(BUILD_NUMBER)
ifneq ($(BUILD),)
HIVE_TAR=thehive_$(HIVE_VERSION)_$(BUILD).tar.gz
else
HIVE_TAR=thehive_$(HIVE_VERSION).tar.gz
endif
all: clean build
build: build_analyzers build_thehive build_shuffle
build_analyzers:
	echo "Starting custom analyzer, responders build #$(BUILD)"
	
	mkdir -p $(BUILD_DIR); mkdir -p $(OUT_DIR);
	cd $(PLUGINS_DIR); ./build.sh
	cd $(PLUGINS_DIR);  tar -czvf plugins.tar.gz *.tar
	mv $(PLUGINS_DIR)/*.tar.gz $(OUT_DIR)/
    
	mv $(PLUGINS_DIR)/analyzers/analyzers.json $(DOCKER_DIR)/vol/cortex
	mv $(PLUGINS_DIR)/responders/responders.json $(DOCKER_DIR)/vol/cortex
	
	echo "Custom Analyzers, Responders generated successfully."
	
build_shuffle:
	echo "Starting shuffle build #$(BUILD)"
	mkdir -p $(BUILD_DIR); mkdir -p $(OUT_DIR);
	
	sed -i '/BACKEND_VERSION/c\' $(SHUFFLE_DOCKER_DIR)/.env
	echo BACKEND_VERSION=$(BACKEND_VERSION) >> $(SHUFFLE_DOCKER_DIR)/.env
	sed -i '/FRONTEND_VERSION/c\' $(SHUFFLE_DOCKER_DIR)/.env
	echo FRONTEND_VERSION=$(FRONTEND_VERSION) >> $(SHUFFLE_DOCKER_DIR)/.env
	sed -i '/ORBORUS_VERSION/c\' $(SHUFFLE_DOCKER_DIR)/.env
	echo ORBORUS_VERSION=$(ORBORUS_VERSION) >> $(SHUFFLE_DOCKER_DIR)/.env
        
	cd Shuffle/Docker/; ./build_shuffle.sh false
	mv Shuffle/Docker/*.tar.gz $(OUT_DIR)/
	cp Shuffle/Docker/deploy_shuffle.sh $(OUT_DIR)/
	echo "The Shuffle deployment bundle is generated successfully."
build_thehive:
	echo "Starting thehive build #${BUILD}"
	mkdir -p $(BUILD_DIR); mkdir -p $(OUT_DIR);
	
	sed -i '/HIVE_VERSION/c\' $(DOCKER_DIR)/.env
	echo HIVE_VERSION=$(HIVE_VERSION) >> $(DOCKER_DIR)/.env
	sed -i '/CORTEX_VERSION/c\' $(DOCKER_DIR)/.env
	echo CORTEX_VERSION=$(CORTEX_VERSION) >> $(DOCKER_DIR)/.env
	sed -i '/ELASTICSEARCH_VERSION/c\' $(DOCKER_DIR)/.env
	echo ELASTICSEARCH_VERSION=$(ELASTICSEARCH_VERSION) >> $(DOCKER_DIR)/.env
	sed -i '/CASSANDRA_VERSION/c\' $(DOCKER_DIR)/.env
	echo CASSANDRA_VERSION=$(CASSANDRA_VERSION) >> $(DOCKER_DIR)/.env
	sed -i '/NGINX_VERSION/c\' $(DOCKER_DIR)/.env
	echo NGINX_VERSION=$(NGINX_VERSION) >> $(DOCKER_DIR)/.env
	cp -a $(DOCKER_DIR) $(TMP_DOCKER_DIR); 
	cd $(TMP_DOCKER_DIR); sed -i '/server_name/c\server_name $(THEHIVE_SERVER_NAME)' vol/nginx/thehive.conf
	cd $(TMP_DOCKER_DIR); sed -i '/server_name/c\server_name $(CORTEX_SERVER_NAME)' vol/nginx/cortex.conf
	cd $(TMP_DOCKER_DIR);  docker-compose up -d
	
	docker commit $$( docker ps | grep thehive4 | awk '{print $$1}') $$(docker image ls | grep thehive4 | grep $(HIVE_VERSION) | awk '{print $$1}'):$(HIVE_VERSION)
	docker commit $$( docker ps | grep cortex | awk '{print $$1}') $$(docker image ls | grep cortex | grep $(CORTEX_VERSION) | awk '{print $$1}'):$(CORTEX_VERSION)
	docker image save $$( docker image ls | grep thehive4 | grep $(HIVE_VERSION) | awk '{print $$3}') -o $(BUILD_DIR)/thehive_$(HIVE_VERSION).tar thehiveproject/thehive4:$(HIVE_VERSION)
	docker image save $$( docker image ls | grep cortex | grep $(CORTEX_VERSION) | awk '{print $$3}') -o $(BUILD_DIR)/cortex_$(CORTEX_VERSION).tar thehiveproject/cortex:$(CORTEX_VERSION)
	
	docker image save $$( docker image ls | grep elasticsearch | grep $(ELASTICSEARCH_VERSION) | awk '{print $$3}') -o $(BUILD_DIR)/elasticsearch.tar elasticsearch:$(ELASTICSEARCH_VERSION)
	docker image save $$( docker image ls | grep nginx | grep $(NGINX_VERSION) | awk '{print $$3}') -o $(BUILD_DIR)/nginx.tar nginx:$(NGINX_VERSION)  
	docker image save $$( docker image ls | grep cassandra | grep $(CASSANDRA_VERSION) | awk '{print $$3}') -o $(BUILD_DIR)/cassandra.tar cassandra:$(CASSANDRA_VERSION)  
	
	cd $(BUILD_DIR);  tar -czvf $(HIVE_TAR) *.tar
	mv $(BUILD_DIR)/*.tar.gz $(OUT_DIR)/
	cp -r $(DOCKER_DIR) $(OUT_DIR)/
	cp docker/deploy_soar.sh $(OUT_DIR)/
	cp -r playbooks $(OUT_DIR)/
	echo "TheHive deployment bundle " $(OUT_DIR)/$(HIVE_TAR) "generated successfully."
clean:
	rm -rf $(BUILD_DIR);
	[ -e $(TMP_DOCKER_DIR)/docker-compose.yml ] && ( cd $(TMP_DOCKER_DIR); docker-compose down -v --rmi all --remove-orphans; echo SUCCESS ) || echo "No docker-compose.yml to clean"
	# Remove temp docker folder
	sudo rm -rf $(TMP_DOCKER_DIR)
	# Remove the shuffle temp folder
	sudo rm -rf Shuffle/Docker/docker-shuffle/shuffle-database
	sudo rm -rf Shuffle/Docker/docker-shuffle/shuffle-files
	#Remove docker images of analyzers and responders
	sudo rm -rf $(PLUGINS_DIR)/*.tar
	docker rmi -f  $$( docker image ls | grep acds-mailer | awk '{print $$3}' ) || true
	docker container stop $$( docker container ls | grep registry | awk '{print $$1}') || true
	docker rmi -f  $$( docker image ls | grep registry | awk '{print $$3}' ) || true
cleanall:
	# stop all containers
	( docker container stop $$(docker container ls -aq) ) && ( echo "Stopped Containers" ) 
	# remove all containers
	( docker container rm $$(docker container ls -aq) ) && ( echo "Removed Containers" ) 
	# remove all images
	( docker rmi -f $$(docker images -a -q) ) && ( echo "Removed Images" ) 
	# remove all volumes
	( docker volume rm $$(docker volume ls -q) ) && ( echo "Remove Volumes" ) 
	
.PHONY: clean build build_analyzers build_thehive build_shuffle all
